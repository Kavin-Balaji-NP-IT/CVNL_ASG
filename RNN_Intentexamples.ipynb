{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z2aqw5zu_Qth"
      },
      "outputs": [],
      "source": [
        "# Intent examples\n",
        "#1.\tFlight status / gate change questions\n",
        "#2.\tBaggage issue (lost/damaged/delayed)\n",
        "#3.\tDirections within terminal (immigration, Jewel, transfer, lounges)\n",
        "#4.\tSpecial assistance request (wheelchair assistance, family/infant support)\n",
        "#5.\tTransport / ground connectivity questions\n",
        "#6.\tSecurity/customs related general queries (high-level only; no sensitive/security bypass content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk6Z5E-9Djl2",
        "outputId": "1bd65b1a-5a1a-421c-a431-beee147087cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading SNIPS dataset from HuggingFace...\")\n",
        "ds = load_dataset(\"DeepPavlov/snips\", \"default\")\n",
        "\n",
        "print(\"\\nDataset structure:\")\n",
        "print(ds)\n",
        "\n",
        "# Explore the dataset\n",
        "print(\"\\nTraining set info:\")\n",
        "print(f\"Number of samples: {len(ds['train'])}\")\n",
        "print(f\"\\nSample entry:\")\n",
        "print(ds['train'][0])\n",
        "\n",
        "print(\"\\nValidation set info:\")\n",
        "print(f\"Number of samples: {len(ds['validation'])}\")\n",
        "\n",
        "print(\"\\nTest set info:\")\n",
        "print(f\"Number of samples: {len(ds['test'])}\")\n",
        "\n",
        "# Get label names\n",
        "label_names = ds['train'].features['label'].names\n",
        "print(f\"\\nOriginal SNIPS intents ({len(label_names)}):\")\n",
        "for i, label in enumerate(label_names):\n",
        "    print(f\"  {i}: {label}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "m-cN86mqFiz4",
        "outputId": "cddcfb6e-a231-4464-c67a-4f6191dd5778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SNIPS dataset from HuggingFace...\n",
            "\n",
            "Dataset structure:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['utterance', 'label'],\n",
            "        num_rows: 13084\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['utterance', 'label'],\n",
            "        num_rows: 1400\n",
            "    })\n",
            "})\n",
            "\n",
            "Training set info:\n",
            "Number of samples: 13084\n",
            "\n",
            "Sample entry:\n",
            "{'utterance': 'Add Don and Sherri to my Meditate to Sounds of Nature playlist', 'label': 0}\n",
            "\n",
            "Validation set info:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'validation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-867349724.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nValidation set info:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of samples: {len(ds['validation'])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTest set info:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamedSplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             available_suggested_splits = [\n",
            "\u001b[0;31mKeyError\u001b[0m: 'validation'"
          ]
        }
      ]
    }
  ]
}