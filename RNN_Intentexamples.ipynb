{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Changi Virtual Assist Triage - RNN Text Classification\n",
        "Using ATIS Dataset from Hugging Face\n",
        "\n",
        "Fixed version using: from datasets import load_dataset\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 1: Setup and Imports\n",
        "# ============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 2: Load ATIS Dataset\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Loading ATIS dataset from Hugging Face...\")\n",
        "ds = load_dataset(\"tuetschek/atis\")\n",
        "\n",
        "# Extract data from dataset and convert to lists\n",
        "train_texts = list(ds['train']['text'])\n",
        "train_labels_raw = list(ds['train']['intent'])\n",
        "\n",
        "test_texts = list(ds['test']['text'])\n",
        "test_labels_raw = list(ds['test']['intent'])\n",
        "\n",
        "# Create validation split from training data (10%)\n",
        "val_size = int(0.1 * len(train_texts))\n",
        "val_texts = train_texts[:val_size]\n",
        "val_labels_raw = train_labels_raw[:val_size]\n",
        "train_texts = train_texts[val_size:]\n",
        "train_labels_raw = train_labels_raw[val_size:]\n",
        "\n",
        "print(f\"\\nDataset loaded successfully!\")\n",
        "print(f\"  Train: {len(train_texts)} samples\")\n",
        "print(f\"  Val:   {len(val_texts)} samples\")\n",
        "print(f\"  Test:  {len(test_texts)} samples\")\n",
        "\n",
        "# Get unique intents and create mapping\n",
        "all_intents = sorted(list(set(train_labels_raw + test_labels_raw + val_labels_raw)))\n",
        "intent_to_idx = {intent: idx for idx, intent in enumerate(all_intents)}\n",
        "idx_to_intent = {idx: intent for intent, idx in intent_to_idx.items()}\n",
        "\n",
        "NUM_CLASSES = len(intent_to_idx)\n",
        "\n",
        "# Convert intent strings to indices\n",
        "train_labels = [intent_to_idx[intent] for intent in train_labels_raw]\n",
        "val_labels = [intent_to_idx[intent] for intent in val_labels_raw]\n",
        "test_labels = [intent_to_idx[intent] for intent in test_labels_raw]\n",
        "\n",
        "print(f\"\\nNumber of unique intents: {NUM_CLASSES}\")\n",
        "print(f\"\\nTop 15 most common intents:\")\n",
        "intent_counts = Counter(train_labels_raw)\n",
        "for i, (intent, count) in enumerate(intent_counts.most_common(15), 1):\n",
        "    print(f\"  {i:2d}. {intent:<35} {count:>4} samples\")\n",
        "\n",
        "# Display distribution\n",
        "print(\"\\nTrain label distribution:\")\n",
        "train_dist = Counter(train_labels)\n",
        "for i in sorted(train_dist.keys())[:10]:\n",
        "    intent = idx_to_intent[i]\n",
        "    count = train_dist[i]\n",
        "    print(f\"  {intent:<35} {count:>4}\")\n",
        "\n",
        "# Show sample queries\n",
        "print(\"\\nSample queries (first 10):\")\n",
        "for i in range(min(10, len(train_texts))):\n",
        "    print(f\"  {i+1:2d}. [{idx_to_intent[train_labels[i]]:<30}] '{train_texts[i][:60]}...'\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 3: Text Preprocessing\n",
        "# ============================================================================\n",
        "\n",
        "class TextPreprocessor:\n",
        "    \"\"\"Text preprocessing and vocabulary management\"\"\"\n",
        "    def __init__(self):\n",
        "        self.vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "        self.word_to_idx = self.vocab.copy()\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Clean and normalize text\"\"\"\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
        "        return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Tokenize text into words\"\"\"\n",
        "        return text.split()\n",
        "\n",
        "    def build_vocab(self, texts, min_freq=2):\n",
        "        \"\"\"Build vocabulary from texts\"\"\"\n",
        "        word_freq = Counter()\n",
        "        for text in texts:\n",
        "            word_freq.update(self.tokenize(self.clean_text(text)))\n",
        "\n",
        "        for word, freq in word_freq.items():\n",
        "            if freq >= min_freq and word not in self.word_to_idx:\n",
        "                self.word_to_idx[word] = len(self.word_to_idx)\n",
        "\n",
        "        print(f\"\\nVocabulary built!\")\n",
        "        print(f\"  Vocab size: {len(self.word_to_idx)} (min_freq={min_freq})\")\n",
        "        return self.word_to_idx\n",
        "\n",
        "    def text_to_indices(self, text):\n",
        "        \"\"\"Convert text to indices\"\"\"\n",
        "        tokens = self.tokenize(self.clean_text(text))\n",
        "        return [self.word_to_idx.get(t, 1) for t in tokens]  # 1 is <UNK>\n",
        "\n",
        "# Build vocabulary from training data\n",
        "preprocessor = TextPreprocessor()\n",
        "preprocessor.build_vocab(train_texts, min_freq=2)\n",
        "\n",
        "# Analyze sequence lengths\n",
        "lengths = [len(preprocessor.text_to_indices(t)) for t in train_texts]\n",
        "print(f\"\\nSequence length statistics:\")\n",
        "print(f\"  Mean: {np.mean(lengths):.1f}\")\n",
        "print(f\"  Median: {np.median(lengths):.0f}\")\n",
        "print(f\"  Max: {np.max(lengths)}\")\n",
        "print(f\"  Min: {np.min(lengths)}\")\n",
        "print(f\"  95th percentile: {np.percentile(lengths, 95):.0f}\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 4: PyTorch Dataset\n",
        "# ============================================================================\n",
        "\n",
        "class IntentDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for intent classification\"\"\"\n",
        "    def __init__(self, texts, labels, preprocessor):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        indices = self.preprocessor.text_to_indices(self.texts[idx])\n",
        "        return {\n",
        "            'indices': torch.LongTensor(indices),\n",
        "            'label': torch.LongTensor([self.labels[idx]]),\n",
        "            'length': len(indices)\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function for DataLoader\"\"\"\n",
        "    indices = pad_sequence([b['indices'] for b in batch], batch_first=True)\n",
        "    labels = torch.cat([b['label'] for b in batch])\n",
        "    lengths = torch.LongTensor([b['length'] for b in batch])\n",
        "    return {'indices': indices, 'labels': labels, 'lengths': lengths}\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = IntentDataset(train_texts, train_labels, preprocessor)\n",
        "val_dataset = IntentDataset(val_texts, val_labels, preprocessor)\n",
        "test_dataset = IntentDataset(test_texts, test_labels, preprocessor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, BATCH_SIZE, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"\\nDataLoaders created:\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Val batches:   {len(val_loader)}\")\n",
        "print(f\"  Test batches:  {len(test_loader)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 5: RNN Model\n",
        "# ============================================================================\n",
        "\n",
        "class IntentRNN(nn.Module):\n",
        "    \"\"\"Bidirectional LSTM for Intent Classification\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes,\n",
        "                 num_layers=2, dropout=0.4, bidirectional=True):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.emb_dropout = nn.Dropout(0.2)\n",
        "\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers,\n",
        "                           dropout=dropout if num_layers > 1 else 0,\n",
        "                           bidirectional=bidirectional, batch_first=True)\n",
        "\n",
        "        fc_input = hidden_dim * (2 if bidirectional else 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(fc_input, num_classes)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # Embedding layer\n",
        "        embedded = self.embedding(x)\n",
        "        embedded = self.emb_dropout(embedded)\n",
        "\n",
        "        # Pack padded sequence for efficient LSTM processing\n",
        "        packed = pack_padded_sequence(embedded, lengths.cpu(),\n",
        "                                     batch_first=True, enforce_sorted=False)\n",
        "        _, (hidden, _) = self.lstm(packed)\n",
        "\n",
        "        # Concatenate forward and backward hidden states\n",
        "        if self.bidirectional:\n",
        "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "        else:\n",
        "            hidden = hidden[-1]\n",
        "\n",
        "        # Classification layer\n",
        "        out = self.dropout(hidden)\n",
        "        return self.fc(out)\n",
        "\n",
        "# Initialize model\n",
        "VOCAB_SIZE = len(preprocessor.word_to_idx)\n",
        "model = IntentRNN(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embed_dim=128,           # Increased from 64\n",
        "    hidden_dim=256,          # Increased from 128\n",
        "    num_classes=NUM_CLASSES,\n",
        "    num_layers=2,\n",
        "    dropout=0.3,             # Reduced from 0.4\n",
        "    bidirectional=True\n",
        ").to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel Architecture:\")\n",
        "print(model)\n",
        "print(f\"\\nModel Statistics:\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 6: Training Functions\n",
        "# ============================================================================\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for batch in loader:\n",
        "        indices = batch['indices'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        lengths = batch['lengths']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(indices, lengths)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return total_loss / len(loader), 100 * correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    \"\"\"Evaluate the model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            indices = batch['indices'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            lengths = batch['lengths']\n",
        "\n",
        "            outputs = model(indices, lengths)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return total_loss / len(loader), 100 * correct / total, all_preds, all_labels\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 7: Training Loop\n",
        "# ============================================================================\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "\n",
        "EPOCHS = 20\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "best_val_acc = 0\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STARTING TRAINING\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:2d}/{EPOCHS}\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:6.2f}%\")\n",
        "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:6.2f}%\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_model_atis.pth')\n",
        "        print(f\"  âœ“ New best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
        "    print()\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Training completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 8: Test Evaluation\n",
        "# ============================================================================\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load('best_model_atis.pth'))\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc, y_pred, y_true = evaluate(model, test_loader, criterion)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TEST SET EVALUATION\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "# Detailed classification report\n",
        "# Only include intents that appear in test set\n",
        "unique_test_labels = sorted(list(set(y_true)))\n",
        "intent_names_in_test = [idx_to_intent[i] for i in unique_test_labels]\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "print(classification_report(y_true, y_pred, labels=unique_test_labels,\n",
        "                           target_names=intent_names_in_test, zero_division=0))\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 9: Confusion Matrix\n",
        "# ============================================================================\n",
        "\n",
        "# Get top 15 most common intents for visualization\n",
        "top_15_intents = [intent for intent, _ in Counter([idx_to_intent[i] for i in y_true]).most_common(15)]\n",
        "top_15_indices = [intent_to_idx[intent] for intent in top_15_intents]\n",
        "\n",
        "# Filter predictions and labels for top 15\n",
        "filtered_true = [y for y in y_true if y in top_15_indices]\n",
        "filtered_pred = [y_pred[i] for i, y in enumerate(y_true) if y in top_15_indices]\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(filtered_true, filtered_pred, labels=top_15_indices)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[intent[:25] for intent in top_15_intents],\n",
        "            yticklabels=[intent[:25] for intent in top_15_intents])\n",
        "plt.title('Confusion Matrix - Top 15 Most Common Intents')\n",
        "plt.ylabel('True Intent')\n",
        "plt.xlabel('Predicted Intent')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix_atis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\nâœ“ Confusion matrix saved as 'confusion_matrix_atis.png'\")\n",
        "plt.close()\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 10: Training Curves\n",
        "# ============================================================================\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(history['train_loss'], label='Train Loss', marker='o', markersize=4)\n",
        "ax1.plot(history['val_loss'], label='Val Loss', marker='s', markersize=4)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(history['train_acc'], label='Train Acc', marker='o', markersize=4)\n",
        "ax2.plot(history['val_acc'], label='Val Acc', marker='s', markersize=4)\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_curves_atis.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ“ Training curves saved as 'training_curves_atis.png'\\n\")\n",
        "plt.close()\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 11: Prediction Function\n",
        "# ============================================================================\n",
        "\n",
        "def predict_intent(text, model=model, preprocessor=preprocessor, top_k=3):\n",
        "    \"\"\"\n",
        "    Predict intent for a given text query\n",
        "\n",
        "    Args:\n",
        "        text: Input query string\n",
        "        model: Trained model\n",
        "        preprocessor: Text preprocessor\n",
        "        top_k: Number of top predictions to return\n",
        "\n",
        "    Returns:\n",
        "        List of (intent, confidence) tuples\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocess text\n",
        "    indices = preprocessor.text_to_indices(text)\n",
        "    indices_tensor = torch.LongTensor([indices]).to(device)\n",
        "    length = torch.LongTensor([len(indices)])\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(indices_tensor, length)\n",
        "        probs = torch.softmax(outputs, dim=1)[0]\n",
        "        top_probs, top_indices = torch.topk(probs, min(top_k, NUM_CLASSES))\n",
        "\n",
        "    # Format results\n",
        "    results = []\n",
        "    for prob, idx in zip(top_probs.cpu().numpy(), top_indices.cpu().numpy()):\n",
        "        results.append({\n",
        "            'intent': idx_to_intent[int(idx)],\n",
        "            'confidence': float(prob) * 100\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 12: Test on Real Airport Queries\n",
        "# ============================================================================\n",
        "\n",
        "test_queries = [\n",
        "    \"What time does my flight to Tokyo depart?\",\n",
        "    \"I can't find my luggage\",\n",
        "    \"Where is gate A15?\",\n",
        "    \"I need wheelchair assistance to my gate\",\n",
        "    \"How do I get to downtown Singapore from here?\",\n",
        "    \"What items can I bring in my carry-on?\",\n",
        "    \"My bag was damaged during the flight\",\n",
        "    \"Where is the immigration counter in Terminal 2?\",\n",
        "    \"Can I get special assistance for traveling with an infant?\",\n",
        "    \"How much does a taxi cost to Marina Bay Sands?\",\n",
        "    \"Do I need to declare alcohol purchases?\",\n",
        "    \"Where can I find a restroom near gate B12?\",\n",
        "    \"What time does boarding start for my flight?\",\n",
        "    \"I need to report a lost bag\",\n",
        "    \"Show me flights to New York\",\n",
        "    \"Where is the SilverKris lounge?\",\n",
        "    \"I need help finding the MRT station\",\n",
        "    \"Can I bring batteries in my luggage?\",\n",
        "    \"My flight has been delayed, what should I do?\",\n",
        "    \"Where can I exchange currency?\"\n",
        "]\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"REAL AIRPORT QUERY PREDICTIONS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(\"-\" * 70)\n",
        "    preds = predict_intent(query, top_k=3)\n",
        "    for i, pred in enumerate(preds, 1):\n",
        "        bar = \"â–ˆ\" * int(pred['confidence'] / 3)\n",
        "        print(f\"  {i}. {pred['intent'][:45]:.<50} {pred['confidence']:>5.1f}%  {bar}\")\n",
        "    print()\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 13: Test on Dataset Examples\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"PREDICTIONS ON TEST SET EXAMPLES\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Show 15 random test examples\n",
        "indices = np.random.choice(len(test_texts), min(15, len(test_texts)), replace=False)\n",
        "\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "for idx in indices:\n",
        "    text = test_texts[idx]\n",
        "    true_label = test_labels[idx]\n",
        "    true_intent = idx_to_intent[true_label]\n",
        "\n",
        "    print(f\"Query: '{text}'\")\n",
        "    print(f\"True: {true_intent}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    preds = predict_intent(text, top_k=3)\n",
        "\n",
        "    for i, pred in enumerate(preds, 1):\n",
        "        marker = \"âœ“\" if pred['intent'] == true_intent else \" \"\n",
        "        bar = \"â–ˆ\" * int(pred['confidence'] / 4)\n",
        "        print(f\"{marker} {i}. {pred['intent'][:45]:.<50} {pred['confidence']:>5.1f}%  {bar}\")\n",
        "\n",
        "        if i == 1 and pred['intent'] == true_intent:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    total_predictions += 1\n",
        "    print()\n",
        "\n",
        "print(f\"Accuracy on shown examples: {100 * correct_predictions / total_predictions:.1f}%\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 14: Error Analysis\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Find misclassified examples\n",
        "misclassified = []\n",
        "for text, true_label, pred_label in zip(test_texts, y_true, y_pred):\n",
        "    if true_label != pred_label:\n",
        "        misclassified.append({\n",
        "            'text': text,\n",
        "            'true': idx_to_intent[true_label],\n",
        "            'predicted': idx_to_intent[pred_label]\n",
        "        })\n",
        "\n",
        "print(f\"Total misclassifications: {len(misclassified)} out of {len(test_texts)}\")\n",
        "print(f\"Test accuracy: {100 * (len(test_texts) - len(misclassified)) / len(test_texts):.2f}%\")\n",
        "\n",
        "if misclassified:\n",
        "    print(f\"\\nMisclassified Examples (showing up to 15):\")\n",
        "    print(\"-\" * 70)\n",
        "    for i, example in enumerate(misclassified[:15], 1):\n",
        "        print(f\"\\n{i:2d}. Query: '{example['text']}'\")\n",
        "        print(f\"    True: {example['true'][:50]}\")\n",
        "        print(f\"    Pred: {example['predicted'][:50]}\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 15: Model Summary\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"MODEL SUMMARY & PERFORMANCE INSIGHTS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(\"Model Architecture:\")\n",
        "print(f\"  Type: Bidirectional LSTM\")\n",
        "print(f\"  Embedding dim: 128\")\n",
        "print(f\"  Hidden dim: 256\")\n",
        "print(f\"  LSTM layers: 2\")\n",
        "print(f\"  Dropout: 0.3\")\n",
        "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "print(f\"\\nDataset Statistics:\")\n",
        "print(f\"  Training samples: {len(train_texts)}\")\n",
        "print(f\"  Validation samples: {len(val_texts)}\")\n",
        "print(f\"  Test samples: {len(test_texts)}\")\n",
        "print(f\"  Vocabulary size: {VOCAB_SIZE}\")\n",
        "print(f\"  Number of intents: {NUM_CLASSES}\")\n",
        "\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"  Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"  Test accuracy: {test_acc:.2f}%\")\n",
        "print(f\"  Training epochs: {len(history['train_loss'])}\")\n",
        "\n",
        "# Calculate per-class metrics (only for intents in test set)\n",
        "precision, recall, f1, support = precision_recall_fscore_support(\n",
        "    y_true, y_pred, labels=unique_test_labels, average=None, zero_division=0\n",
        ")\n",
        "\n",
        "# Show top 10 performing intents\n",
        "print(f\"\\nTop 10 Best Performing Intents (by F1-Score):\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Intent':<45} {'Precision':>10} {'Recall':>10} {'F1-Score':>10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "intent_f1 = [(idx_to_intent[unique_test_labels[i]], f1[i], precision[i], recall[i])\n",
        "             for i in range(len(unique_test_labels))]\n",
        "intent_f1_sorted = sorted(intent_f1, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for intent, f1_score, prec, rec in intent_f1_sorted[:10]:\n",
        "    print(f\"{intent[:45]:<45} {prec:>10.2%} {rec:>10.2%} {f1_score:>10.2%}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 16: Save Complete Model Checkpoint\n",
        "# ============================================================================\n",
        "\n",
        "checkpoint = {\n",
        "    'model_state': model.state_dict(),\n",
        "    'vocab': preprocessor.word_to_idx,\n",
        "    'intent_to_idx': intent_to_idx,\n",
        "    'idx_to_intent': idx_to_intent,\n",
        "    'hyperparameters': {\n",
        "        'vocab_size': VOCAB_SIZE,\n",
        "        'embed_dim': 128,\n",
        "        'hidden_dim': 256,\n",
        "        'num_layers': 2,\n",
        "        'dropout': 0.3,\n",
        "        'bidirectional': True\n",
        "    },\n",
        "    'test_acc': test_acc,\n",
        "    'best_val_acc': best_val_acc,\n",
        "    'training_history': history\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, 'changi_airport_rnn_atis_complete.pth')\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"âœ“ Complete model checkpoint saved as 'changi_airport_rnn_atis_complete.pth'\")\n",
        "print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
        "print(f\"  Best Val Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"\\nTo load the model later, use:\")\n",
        "print(\"  checkpoint = torch.load('changi_airport_rnn_atis_complete.pth')\")\n",
        "print(\"  model.load_state_dict(checkpoint['model_state'])\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 17: Interactive Demo Function\n",
        "# ============================================================================\n",
        "\n",
        "def interactive_demo():\n",
        "    \"\"\"Interactive demo for testing the classifier\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"CHANGI AIRPORT VIRTUAL ASSIST - INTERACTIVE DEMO\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(\"\\nEnter airport service queries to classify (type 'quit' to exit)\")\n",
        "    print(\"\\nExample queries:\")\n",
        "    print(\"  - Where is my gate?\")\n",
        "    print(\"  - My bag is missing\")\n",
        "    print(\"  - How to get downtown?\")\n",
        "    print(\"  - I need wheelchair help\")\n",
        "    print(f\"\\n{'='*70}\\n\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"Enter query: \").strip()\n",
        "\n",
        "        if query.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"\\nThank you for using Changi Virtual Assist!\")\n",
        "            break\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        print(\"\\nPredicted Intents:\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        preds = predict_intent(query, top_k=3)\n",
        "\n",
        "        for i, pred in enumerate(preds, 1):\n",
        "            bar = \"â–ˆ\" * int(pred['confidence'] / 2.5)\n",
        "            print(f\"{i}. {pred['intent'][:45]:.<50} {pred['confidence']:>6.2f}% {bar}\")\n",
        "\n",
        "        print()\n",
        "\n",
        "# Uncomment to run interactive demo:\n",
        "# interactive_demo()\n",
        "\n",
        "# ============================================================================\n",
        "# CELL 18: Usage Instructions\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"HOW TO USE THIS MODEL\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(\"1. Make predictions on new queries:\")\n",
        "print(\"   predictions = predict_intent('where is my luggage?')\")\n",
        "print()\n",
        "\n",
        "print(\"2. Get top-k predictions:\")\n",
        "print(\"   predictions = predict_intent('gate for my flight', top_k=3)\")\n",
        "print()\n",
        "\n",
        "print(\"3. Run interactive demo:\")\n",
        "print(\"   interactive_demo()\")\n",
        "print()\n",
        "\n",
        "print(\"4. Access model components:\")\n",
        "print(\"   - model: The trained RNN model\")\n",
        "print(\"   - preprocessor: Text preprocessing utilities\")\n",
        "print(\"   - idx_to_intent: Intent label mapping\")\n",
        "print()\n",
        "\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(\"âœ… All cells completed successfully!\")\n",
        "print(\"ðŸ“Š Model ready for deployment at Changi Airport Virtual Assist!\")\n",
        "print(f\"\\n{'='*70}\")"
      ],
      "metadata": {
        "id": "ev5aqyV6riYG",
        "outputId": "026c0d1f-622e-41f7-8bd2-e99543998494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Loading ATIS dataset from Hugging Face...\n",
            "\n",
            "Dataset loaded successfully!\n",
            "  Train: 4481 samples\n",
            "  Val:   497 samples\n",
            "  Test:  893 samples\n",
            "\n",
            "Number of unique intents: 26\n",
            "\n",
            "Top 15 most common intents:\n",
            "   1. flight                              3289 samples\n",
            "   2. airfare                              388 samples\n",
            "   3. ground_service                       231 samples\n",
            "   4. airline                              140 samples\n",
            "   5. abbreviation                         135 samples\n",
            "   6. aircraft                              74 samples\n",
            "   7. flight_time                           47 samples\n",
            "   8. quantity                              43 samples\n",
            "   9. flight+airfare                        21 samples\n",
            "  10. distance                              18 samples\n",
            "  11. airport                               18 samples\n",
            "  12. city                                  17 samples\n",
            "  13. ground_fare                           16 samples\n",
            "  14. capacity                              15 samples\n",
            "  15. flight_no                             11 samples\n",
            "\n",
            "Train label distribution:\n",
            "  abbreviation                         135\n",
            "  aircraft                              74\n",
            "  aircraft+flight+flight_no              1\n",
            "  airfare                              388\n",
            "  airfare+flight_time                    1\n",
            "  airline                              140\n",
            "  airline+flight_no                      2\n",
            "  airport                               18\n",
            "  capacity                              15\n",
            "  cheapest                               1\n",
            "\n",
            "Sample queries (first 10):\n",
            "   1. [flight                        ] 'what 's the last flight from houston to dallas...'\n",
            "   2. [flight                        ] 'is there a flight from charlotte to newark on tuesday evenin...'\n",
            "   3. [airline                       ] 'what is airline us...'\n",
            "   4. [airfare                       ] 'what 's the lowest round trip fare from dallas to atlanta...'\n",
            "   5. [flight                        ] 'find me the earliest flight from boston to atlanta on any da...'\n",
            "   6. [flight                        ] 'display all flights from boston to baltimore on july thirty ...'\n",
            "   7. [airfare                       ] 'economy fares new york to miami round trip...'\n",
            "   8. [flight                        ] 'i need to fly from boston to denver on to san francisco and ...'\n",
            "   9. [flight                        ] 'i wish to book a flight from pittsburgh to atlanta coach dis...'\n",
            "  10. [flight                        ] 'show me flights to dallas from san francisco and atlanta and...'\n",
            "\n",
            "Vocabulary built!\n",
            "  Vocab size: 606 (min_freq=2)\n",
            "\n",
            "Sequence length statistics:\n",
            "  Mean: 11.4\n",
            "  Median: 11\n",
            "  Max: 42\n",
            "  Min: 1\n",
            "  95th percentile: 19\n",
            "\n",
            "DataLoaders created:\n",
            "  Train batches: 141\n",
            "  Val batches:   16\n",
            "  Test batches:  28\n",
            "\n",
            "Model Architecture:\n",
            "IntentRNN(\n",
            "  (embedding): Embedding(606, 128, padding_idx=0)\n",
            "  (emb_dropout): Dropout(p=0.2, inplace=False)\n",
            "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=26, bias=True)\n",
            ")\n",
            "\n",
            "Model Statistics:\n",
            "  Total parameters: 2,458,394\n",
            "  Trainable parameters: 2,458,394\n",
            "\n",
            "======================================================================\n",
            "STARTING TRAINING\n",
            "======================================================================\n",
            "\n",
            "Epoch  1/20\n",
            "  Train Loss: 0.7522 | Train Acc:  83.31%\n",
            "  Val Loss:   0.2860 | Val Acc:    91.95%\n",
            "  âœ“ New best model saved! (Val Acc: 91.95%)\n",
            "\n",
            "Epoch  2/20\n",
            "  Train Loss: 0.2443 | Train Acc:  94.00%\n",
            "  Val Loss:   0.1421 | Val Acc:    95.77%\n",
            "  âœ“ New best model saved! (Val Acc: 95.77%)\n",
            "\n",
            "Epoch  3/20\n",
            "  Train Loss: 0.1398 | Train Acc:  96.81%\n",
            "  Val Loss:   0.1227 | Val Acc:    97.18%\n",
            "  âœ“ New best model saved! (Val Acc: 97.18%)\n",
            "\n",
            "Epoch  4/20\n",
            "  Train Loss: 0.0875 | Train Acc:  97.86%\n",
            "  Val Loss:   0.1107 | Val Acc:    97.18%\n",
            "\n",
            "Epoch  5/20\n",
            "  Train Loss: 0.0587 | Train Acc:  98.46%\n",
            "  Val Loss:   0.1060 | Val Acc:    97.18%\n",
            "\n",
            "Epoch  6/20\n",
            "  Train Loss: 0.0344 | Train Acc:  99.11%\n",
            "  Val Loss:   0.0935 | Val Acc:    97.59%\n",
            "  âœ“ New best model saved! (Val Acc: 97.59%)\n",
            "\n",
            "Epoch  7/20\n",
            "  Train Loss: 0.0351 | Train Acc:  98.91%\n",
            "  Val Loss:   0.0777 | Val Acc:    97.79%\n",
            "  âœ“ New best model saved! (Val Acc: 97.79%)\n",
            "\n",
            "Epoch  8/20\n",
            "  Train Loss: 0.0160 | Train Acc:  99.55%\n",
            "  Val Loss:   0.0688 | Val Acc:    97.99%\n",
            "  âœ“ New best model saved! (Val Acc: 97.99%)\n",
            "\n",
            "Epoch  9/20\n",
            "  Train Loss: 0.0133 | Train Acc:  99.62%\n",
            "  Val Loss:   0.0994 | Val Acc:    97.99%\n",
            "\n",
            "Epoch 10/20\n",
            "  Train Loss: 0.0078 | Train Acc:  99.78%\n",
            "  Val Loss:   0.0823 | Val Acc:    97.79%\n",
            "\n",
            "Epoch 11/20\n",
            "  Train Loss: 0.0057 | Train Acc:  99.87%\n",
            "  Val Loss:   0.1003 | Val Acc:    98.39%\n",
            "  âœ“ New best model saved! (Val Acc: 98.39%)\n",
            "\n",
            "Epoch 12/20\n",
            "  Train Loss: 0.0035 | Train Acc:  99.93%\n",
            "  Val Loss:   0.0687 | Val Acc:    98.79%\n",
            "  âœ“ New best model saved! (Val Acc: 98.79%)\n",
            "\n",
            "Epoch 13/20\n",
            "  Train Loss: 0.0013 | Train Acc:  99.98%\n",
            "  Val Loss:   0.1046 | Val Acc:    98.39%\n",
            "\n",
            "Epoch 14/20\n",
            "  Train Loss: 0.0011 | Train Acc: 100.00%\n",
            "  Val Loss:   0.0959 | Val Acc:    98.39%\n",
            "\n",
            "Epoch 15/20\n",
            "  Train Loss: 0.0005 | Train Acc: 100.00%\n",
            "  Val Loss:   0.0983 | Val Acc:    98.59%\n",
            "\n",
            "Epoch 16/20\n",
            "  Train Loss: 0.0006 | Train Acc: 100.00%\n",
            "  Val Loss:   0.1028 | Val Acc:    98.39%\n",
            "\n",
            "Epoch 17/20\n",
            "  Train Loss: 0.0019 | Train Acc:  99.96%\n",
            "  Val Loss:   0.0995 | Val Acc:    98.59%\n",
            "\n",
            "Epoch 18/20\n",
            "  Train Loss: 0.0003 | Train Acc: 100.00%\n",
            "  Val Loss:   0.0974 | Val Acc:    98.59%\n",
            "\n",
            "Epoch 19/20\n",
            "  Train Loss: 0.0005 | Train Acc: 100.00%\n",
            "  Val Loss:   0.1001 | Val Acc:    98.59%\n",
            "\n",
            "Epoch 20/20\n",
            "  Train Loss: 0.0003 | Train Acc: 100.00%\n",
            "  Val Loss:   0.0974 | Val Acc:    98.39%\n",
            "\n",
            "======================================================================\n",
            "Training completed! Best validation accuracy: 98.79%\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Test Loss: 0.3664\n",
            "Test Accuracy: 95.86%\n",
            "\n",
            "======================================================================\n",
            "CLASSIFICATION REPORT\n",
            "======================================================================\n",
            "\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     abbreviation       1.00      1.00      1.00        33\n",
            "         aircraft       1.00      1.00      1.00         9\n",
            "          airfare       0.90      0.98      0.94        48\n",
            "   airfare+flight       0.00      0.00      0.00         1\n",
            "          airline       0.97      1.00      0.99        38\n",
            "          airport       1.00      0.83      0.91        18\n",
            "         capacity       1.00      0.95      0.98        21\n",
            "             city       0.75      0.50      0.60         6\n",
            "         day_name       0.00      0.00      0.00         2\n",
            "         distance       1.00      0.70      0.82        10\n",
            "           flight       0.96      0.99      0.98       632\n",
            "   flight+airfare       0.83      0.42      0.56        12\n",
            "   flight+airline       0.00      0.00      0.00         1\n",
            "        flight_no       1.00      0.88      0.93         8\n",
            "flight_no+airline       0.00      0.00      0.00         1\n",
            "      flight_time       1.00      1.00      1.00         1\n",
            "      ground_fare       1.00      0.86      0.92         7\n",
            "   ground_service       1.00      1.00      1.00        36\n",
            "             meal       0.00      0.00      0.00         6\n",
            "         quantity       0.43      1.00      0.60         3\n",
            "\n",
            "         accuracy                           0.96       893\n",
            "        macro avg       0.69      0.66      0.66       893\n",
            "     weighted avg       0.95      0.96      0.95       893\n",
            "\n",
            "\n",
            "âœ“ Confusion matrix saved as 'confusion_matrix_atis.png'\n",
            "âœ“ Training curves saved as 'training_curves_atis.png'\n",
            "\n",
            "\n",
            "======================================================================\n",
            "REAL AIRPORT QUERY PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "Query: 'What time does my flight to Tokyo depart?'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight_time.......................................  99.7%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. flight............................................   0.1%  \n",
            "  3. flight_no.........................................   0.1%  \n",
            "\n",
            "Query: 'I can't find my luggage'\n",
            "----------------------------------------------------------------------\n",
            "  1. city..............................................  47.1%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft+flight+flight_no.........................  15.3%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  3. ground_service....................................   8.6%  â–ˆâ–ˆ\n",
            "\n",
            "Query: 'Where is gate A15?'\n",
            "----------------------------------------------------------------------\n",
            "  1. city..............................................  92.3%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airline...........................................   5.8%  â–ˆ\n",
            "  3. capacity..........................................   0.3%  \n",
            "\n",
            "Query: 'I need wheelchair assistance to my gate'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight............................................  93.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft+flight+flight_no.........................   3.2%  â–ˆ\n",
            "  3. abbreviation......................................   2.5%  \n",
            "\n",
            "Query: 'How do I get to downtown Singapore from here?'\n",
            "----------------------------------------------------------------------\n",
            "  1. ground_service....................................  97.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. flight............................................   2.6%  \n",
            "  3. ground_fare.......................................   0.3%  \n",
            "\n",
            "Query: 'What items can I bring in my carry-on?'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight............................................  93.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. city..............................................   2.3%  \n",
            "  3. aircraft+flight+flight_no.........................   1.5%  \n",
            "\n",
            "Query: 'My bag was damaged during the flight'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight............................................  83.4%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. abbreviation......................................  14.1%  â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  3. city..............................................   1.0%  \n",
            "\n",
            "Query: 'Where is the immigration counter in Terminal 2?'\n",
            "----------------------------------------------------------------------\n",
            "  1. city..............................................  71.6%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airport...........................................  13.0%  â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  3. airline...........................................   2.9%  \n",
            "\n",
            "Query: 'Can I get special assistance for traveling with an infant?'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft..........................................   0.0%  \n",
            "  3. flight_time.......................................   0.0%  \n",
            "\n",
            "Query: 'How much does a taxi cost to Marina Bay Sands?'\n",
            "----------------------------------------------------------------------\n",
            "  1. airfare...........................................  95.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. capacity..........................................   2.0%  \n",
            "  3. abbreviation......................................   1.2%  \n",
            "\n",
            "Query: 'Do I need to declare alcohol purchases?'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft+flight+flight_no.........................   0.0%  \n",
            "  3. abbreviation......................................   0.0%  \n",
            "\n",
            "Query: 'Where can I find a restroom near gate B12?'\n",
            "----------------------------------------------------------------------\n",
            "  1. city..............................................  75.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. capacity..........................................   6.7%  â–ˆâ–ˆ\n",
            "  3. airline...........................................   4.5%  â–ˆ\n",
            "\n",
            "Query: 'What time does boarding start for my flight?'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight_time.......................................  98.6%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. flight_no.........................................   0.4%  \n",
            "  3. flight............................................   0.3%  \n",
            "\n",
            "Query: 'I need to report a lost bag'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight............................................  48.4%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft+flight+flight_no.........................  30.8%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  3. abbreviation......................................   8.4%  â–ˆâ–ˆ\n",
            "\n",
            "Query: 'Show me flights to New York'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airline...........................................   0.0%  \n",
            "  3. airport...........................................   0.0%  \n",
            "\n",
            "Query: 'Where is the SilverKris lounge?'\n",
            "----------------------------------------------------------------------\n",
            "  1. city..............................................  71.9%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. capacity..........................................   9.5%  â–ˆâ–ˆâ–ˆ\n",
            "  3. airline...........................................   5.7%  â–ˆ\n",
            "\n",
            "Query: 'I need help finding the MRT station'\n",
            "----------------------------------------------------------------------\n",
            "  1. abbreviation......................................  55.5%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft+flight+flight_no.........................  21.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  3. flight............................................  10.2%  â–ˆâ–ˆâ–ˆ\n",
            "\n",
            "Query: 'Can I bring batteries in my luggage?'\n",
            "----------------------------------------------------------------------\n",
            "  1. airport...........................................  52.1%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. city..............................................  32.3%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  3. cheapest..........................................   4.6%  â–ˆ\n",
            "\n",
            "Query: 'My flight has been delayed, what should I do?'\n",
            "----------------------------------------------------------------------\n",
            "  1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft+flight+flight_no.........................   0.0%  \n",
            "  3. flight_no.........................................   0.0%  \n",
            "\n",
            "Query: 'Where can I exchange currency?'\n",
            "----------------------------------------------------------------------\n",
            "  1. city..............................................  46.6%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airline...........................................  16.2%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  3. ground_service....................................   7.2%  â–ˆâ–ˆ\n",
            "\n",
            "======================================================================\n",
            "PREDICTIONS ON TEST SET EXAMPLES\n",
            "======================================================================\n",
            "\n",
            "Query: 'new york to las vegas sunday afternoon'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airfare...........................................   0.0%  \n",
            "  3. airport...........................................   0.0%  \n",
            "\n",
            "Query: 'list fares from washington dc to boston'\n",
            "True: airfare\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. airfare........................................... 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. flight............................................   0.0%  \n",
            "  3. flight+airfare....................................   0.0%  \n",
            "\n",
            "Query: 'i need information on flights from toronto to san diego'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airport...........................................   0.0%  \n",
            "  3. airline...........................................   0.0%  \n",
            "\n",
            "Query: 'a flight from baltimore to san francisco arriving between 5 and 8 pm'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airfare...........................................   0.0%  \n",
            "  3. airport...........................................   0.0%  \n",
            "\n",
            "Query: 'are there any flights from boston to orlando connecting in new york'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airport...........................................   0.0%  \n",
            "  3. flight_time.......................................   0.0%  \n",
            "\n",
            "Query: 'i would like flights from las vegas to san francisco'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airport...........................................   0.0%  \n",
            "  3. airline...........................................   0.0%  \n",
            "\n",
            "Query: 'show me one way flights from milwaukee to orlando on wednesday'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airport...........................................   0.0%  \n",
            "  3. airline...........................................   0.0%  \n",
            "\n",
            "Query: 'how much does it cost to fly on twa from columbus to milwaukee'\n",
            "True: airfare\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. airfare........................................... 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. flight............................................   0.0%  \n",
            "  3. ground_fare.......................................   0.0%  \n",
            "\n",
            "Query: 'list all flights and their fares for all flights between miami and indianapolis'\n",
            "True: flight+airfare\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight+airfare....................................  99.5%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. flight............................................   0.2%  \n",
            "  3. airfare...........................................   0.1%  \n",
            "\n",
            "Query: 'what 's the ground transportation in denver'\n",
            "True: ground_service\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. ground_service.................................... 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. ground_fare.......................................   0.0%  \n",
            "  3. ground_service+ground_fare........................   0.0%  \n",
            "\n",
            "Query: 'what 's the fare for a taxi to denver'\n",
            "True: ground_fare\n",
            "----------------------------------------------------------------------\n",
            "  1. airfare........................................... 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. abbreviation......................................   0.0%  \n",
            "âœ“ 3. ground_fare.......................................   0.0%  \n",
            "\n",
            "Query: 'newark to tampa on friday'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft..........................................   0.0%  \n",
            "  3. airport...........................................   0.0%  \n",
            "\n",
            "Query: 'i need flight information for a flight departing from cleveland to milwaukee wednesday after 6 pm'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. aircraft+flight+flight_no.........................   0.0%  \n",
            "  3. airport...........................................   0.0%  \n",
            "\n",
            "Query: 'list flights from seattle to salt lake city on delta l10'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airport...........................................   0.0%  \n",
            "  3. aircraft+flight+flight_no.........................   0.0%  \n",
            "\n",
            "Query: 'what is the shortest flight from milwaukee to long beach'\n",
            "True: flight\n",
            "----------------------------------------------------------------------\n",
            "âœ“ 1. flight............................................ 100.0%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  2. airport...........................................   0.0%  \n",
            "  3. airline...........................................   0.0%  \n",
            "\n",
            "Accuracy on shown examples: 93.3%\n",
            "\n",
            "======================================================================\n",
            "ERROR ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "Total misclassifications: 37 out of 893\n",
            "Test accuracy: 95.86%\n",
            "\n",
            "Misclassified Examples (showing up to 15):\n",
            "----------------------------------------------------------------------\n",
            "\n",
            " 1. Query: 'show flight and prices kansas city to chicago on next wednesday arriving in chicago by 7 pm'\n",
            "    True: flight+airfare\n",
            "    Pred: flight\n",
            "\n",
            " 2. Query: 'what day of the week do flights from nashville to tacoma fly on'\n",
            "    True: day_name\n",
            "    Pred: flight\n",
            "\n",
            " 3. Query: 'what days of the week do flights from san jose to nashville fly on'\n",
            "    True: day_name\n",
            "    Pred: flight\n",
            "\n",
            " 4. Query: 'what meals are served on american flight 811 from tampa to milwaukee'\n",
            "    True: meal\n",
            "    Pred: airfare\n",
            "\n",
            " 5. Query: 'what meals are served on american flight 665 673 from milwaukee to seattle'\n",
            "    True: meal\n",
            "    Pred: flight\n",
            "\n",
            " 6. Query: 'to what cities from boston does america west fly first class'\n",
            "    True: city\n",
            "    Pred: airfare\n",
            "\n",
            " 7. Query: 'what 's the fare for a taxi to denver'\n",
            "    True: ground_fare\n",
            "    Pred: airfare\n",
            "\n",
            " 8. Query: 'which airport is closest to ontario california'\n",
            "    True: airport\n",
            "    Pred: flight\n",
            "\n",
            " 9. Query: 'what meals are available on dl 468 which al arrives in san francisco at 950 am'\n",
            "    True: meal\n",
            "    Pred: flight\n",
            "\n",
            "10. Query: 'list all sunday flights from cleveland to nashville and their fares'\n",
            "    True: flight+airfare\n",
            "    Pred: flight\n",
            "\n",
            "11. Query: 'list the airfare for american airlines flight 19 from jfk to lax'\n",
            "    True: airfare+flight\n",
            "    Pred: airfare\n",
            "\n",
            "12. Query: 'list the distance in miles from boston airport to downtown boston'\n",
            "    True: distance\n",
            "    Pred: flight\n",
            "\n",
            "13. Query: 'list the distance in miles from san francisco international airport to san francisco downtown'\n",
            "    True: distance\n",
            "    Pred: flight\n",
            "\n",
            "14. Query: 'what meals are there on flight 382 from milwaukee to washington dc on tuesday morning'\n",
            "    True: meal\n",
            "    Pred: flight\n",
            "\n",
            "15. Query: 'i need a round trip flight from san diego to washington dc and the fares'\n",
            "    True: flight+airfare\n",
            "    Pred: flight\n",
            "\n",
            "======================================================================\n",
            "MODEL SUMMARY & PERFORMANCE INSIGHTS\n",
            "======================================================================\n",
            "\n",
            "Model Architecture:\n",
            "  Type: Bidirectional LSTM\n",
            "  Embedding dim: 128\n",
            "  Hidden dim: 256\n",
            "  LSTM layers: 2\n",
            "  Dropout: 0.3\n",
            "  Total parameters: 2,458,394\n",
            "\n",
            "Dataset Statistics:\n",
            "  Training samples: 4481\n",
            "  Validation samples: 497\n",
            "  Test samples: 893\n",
            "  Vocabulary size: 606\n",
            "  Number of intents: 26\n",
            "\n",
            "Performance Metrics:\n",
            "  Best validation accuracy: 98.79%\n",
            "  Test accuracy: 95.86%\n",
            "  Training epochs: 20\n",
            "\n",
            "Top 10 Best Performing Intents (by F1-Score):\n",
            "----------------------------------------------------------------------\n",
            "Intent                                         Precision     Recall   F1-Score\n",
            "----------------------------------------------------------------------\n",
            "abbreviation                                     100.00%    100.00%    100.00%\n",
            "aircraft                                         100.00%    100.00%    100.00%\n",
            "flight_time                                      100.00%    100.00%    100.00%\n",
            "ground_service                                   100.00%    100.00%    100.00%\n",
            "airline                                           97.44%    100.00%     98.70%\n",
            "flight                                            96.16%     99.05%     97.58%\n",
            "capacity                                         100.00%     95.24%     97.56%\n",
            "airfare                                           90.38%     97.92%     94.00%\n",
            "flight_no                                        100.00%     87.50%     93.33%\n",
            "ground_fare                                      100.00%     85.71%     92.31%\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "âœ“ Complete model checkpoint saved as 'changi_airport_rnn_atis_complete.pth'\n",
            "  Test Accuracy: 95.86%\n",
            "  Best Val Accuracy: 98.79%\n",
            "\n",
            "To load the model later, use:\n",
            "  checkpoint = torch.load('changi_airport_rnn_atis_complete.pth')\n",
            "  model.load_state_dict(checkpoint['model_state'])\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "HOW TO USE THIS MODEL\n",
            "======================================================================\n",
            "\n",
            "1. Make predictions on new queries:\n",
            "   predictions = predict_intent('where is my luggage?')\n",
            "\n",
            "2. Get top-k predictions:\n",
            "   predictions = predict_intent('gate for my flight', top_k=3)\n",
            "\n",
            "3. Run interactive demo:\n",
            "   interactive_demo()\n",
            "\n",
            "4. Access model components:\n",
            "   - model: The trained RNN model\n",
            "   - preprocessor: Text preprocessing utilities\n",
            "   - idx_to_intent: Intent label mapping\n",
            "\n",
            "======================================================================\n",
            "\n",
            "âœ… All cells completed successfully!\n",
            "ðŸ“Š Model ready for deployment at Changi Airport Virtual Assist!\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}